# ğŸ® Project LANTERN  
### Multi-Agent OCR, Reconstruction & Insight Extraction System  
**Built for the Google AI Agents Intensive â€” 2025 Capstone**

Project LANTERN is a production-inspired, multi-agent pipeline that transforms noisy, unstructured document archives into clean, enriched, searchable intelligence.

Designed for **performance**, **traceability**, and **clarity**, the system uses modular agents to:

- ğŸ” Perform OCR (Gemini Vision â†’ OpenAI â†’ Local Mock fallback)
- ğŸ§µ Reconstruct multi-page threads from manifest metadata
- ğŸ§  Extract structured insights, summaries, entities, and metadata
- ğŸ—‚ Build a fast DuckDB search database  
- ğŸ“Š Present OCR + structured enrichment via interactive notebooks

This project demonstrates **real-world multi-agent system design**, **resilient fallback paths**, and a **polished, end-to-end data pipeline** fit for enterprise scenarios.

---

## ğŸ“ Architecture Overview

Below is the core project flow as a **Mermaid system diagram** (renders automatically on GitHub):

flowchart TD
    A[Raw scans (JPG/PNG)] --> B[OCR Agent (Gemini / OpenAI / Mock)]
    B --> C[OCR outputs: raw_text, clean_text, confidence]
    C --> D[Threading Agent (sequence grouping)]
    D --> E[Extraction Agent: summaries, entities, search_text]
    E --> F[JSONL exports: pages.jsonl, sequences.jsonl]
    F --> G[DuckDB index (lantern.duckdb)]
    G --> H[Search & filtering (keyword + metadata)]
    E --> I[Notebook visualizations (image + OCR + insights)]

---

## ğŸ§© System Architecture

<div align="center">
  <img src="figures/project_lantern_architecture_diagram.png" 
       alt="Project LANTERN Multi-Agent Architecture Diagram" 
       width="750">

  <br/>
  <em>Figure 1 â€” High-level multi-agent architecture powering OCR, sequencing, enrichment, and search.</em>
</div>

---

## ğŸ” Searchable Intelligence Flow Diagram

<div align="center">
  <img src="figures/searchable_intelligence_flow_diagram.png" 
       alt="Searchable Intelligence Flow Diagram" 
       width="750">

  <br/>
  <em>Figure 2 â€” How raw OCR output transforms into a structured, searchable intelligence layer.</em>
</div>

---

## ğŸ“¦ Project Structure

project-lantern-agents-capstone/
â”‚
â”œâ”€â”€ agents/                          
â”‚   â”œâ”€â”€ ocr_agent.py                     # Backend-agnostic OCR (Gemini â†’ OpenAI â†’ Mock)
â”‚   â”œâ”€â”€ threading_agent.py               # Manifest-based thread reconstruction
â”‚   â””â”€â”€ extraction_agent.py              # Summaries, entities, enrichment
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline.py                      # Full pipeline runner (OCR â†’ thread â†’ extract)
â”‚   â”œâ”€â”€ search_index.py                  # DuckDB search index builder
â”‚   â””â”€â”€ utils_env.py                     # Environment + configuration loader
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ cleanup_tools.py                 # Text normalization helpers
â”‚   â”œâ”€â”€ ocr_tools.py                     # OCR fallback + utility functions
â”‚   â””â”€â”€ jsonl_tools.py                   # JSONL read/write helpers
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ manifest.csv                     # Demo subset manifest
â”‚   â”œâ”€â”€ images/                          # Input demo images (user-provided)
â”‚   â””â”€â”€ outputs/
â”‚       â”œâ”€â”€ pages.jsonl                  # Page-level enriched OCR records
â”‚       â””â”€â”€ sequences.jsonl              # Thread-level reconstructed records
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ demo.ipynb                       # Demo subset walkthrough
â”‚   â”œâ”€â”€ project_lantern_capstone.ipynb   # Full capstone notebook
â”‚   â””â”€â”€ 0_Setup_and_Environment.ipynb
â”‚
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ project_lantern_architecture_diagram.png
â”‚   â”œâ”€â”€ searchable_intelligence_flow_diagram.png
â”‚   â””â”€â”€ project_lantern_thumbnail.png
â”‚
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore


---

## ğŸš€ Key Features (Judge-Facing Summary)
ğŸ” 1. OCR Agent â€” Resilient, Backend-Agnostic

- Gemini Vision â†’ preferred
- OpenAI Vision â†’ fallback
- Local deterministic stub â†’ guaranteed execution
- Uniform output schema:

{
  "raw_text": "...",
  "clean_text": "...",
  "confidence": 0.91,
  "error": null
}

---

## ğŸ§µ 2. Thread Reconstruction Agent

- Uses manifest metadata (sequence_id, sequence_order)
- Gracefully handles missing fields
- Produces consistent sequence maps for extraction workflows
- Detects singletons automatically

---

## ğŸ§  3. Extraction Agent â€” Intelligent, Deterministic, Replaceable

- Page-level summaries
- Sequence-level summaries
- Lightweight entity extraction
- Search-ready search_text
- Deterministic mode (no LLM needed)
- Optional LLM-enhanced mode

---

## ğŸ—‚ 4. DuckDB Search Database

- Fast, portable, single-file DB
- Indexes:
* OCR text
* Entities
* Categories
* Document types
* Summaries

Perfect for demonstration and extension.

---

## ğŸ“Š 5. Notebook Visual Experience

- Side-by-side: scanned image + OCR + insights
- DuckDB search walkthrough
- Thread-level analysis

---

## ğŸ” Environment & Authentication

Project LANTERN uses a .env file to keep credentials safe and portable.

.env Template (Do NOT commit real keys)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Project LANTERN â€” Environment Configuration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# --- OpenAI (optional fallback OCR) ---
OPENAI_API_KEY="YOUR_OPENAI_API_KEY_HERE"

# --- Google Gemini / Vertex AI ---
# Primary Vertex API key
GCP_API_KEY="YOUR_VERTEX_API_KEY_HERE"

# Optional Gemini Studio key
GOOGLE_API_KEY="YOUR_GEMINI_STUDIO_KEY_HERE"

# GCP Project Info
GCP_PROJECT_ID="gen-lang-client-0048713898"
GCP_LOCATION="us-central1"

# Service account JSON (for IAM auth only)
GOOGLE_APPLICATION_CREDENTIALS=""

# Models
GEMINI_OCR_MODEL="gemini-1.5-flash"
GEMINI_VISION_MODEL="gemini-1.5-pro"

# Feature Flags
USE_OCR_CACHE="true"
ENABLE_ENTITIES="true"
ENABLE_SEQUENCE_SUMMARY="true"
ENABLE_DEBUG_LOGS="false"

# Pipeline Settings
OCR_TIMEOUT_SECONDS="30"
MAX_OCR_RETRIES="2"
MAX_SUMMARY_CHARS="600"

# Paths
PROJECT_ROOT="./"
DATA_ROOT="./data"
OCR_CACHE_DIR="./data/ocr_cache"
EXPORT_DIR="./data/outputs"

---

## ğŸ”„ Authentication Rules (Local vs Kaggle vs GCP)

| Environment | Recommended Auth              | Key to Use                       | Notes                                     |
| ----------- | ----------------------------- | -------------------------------- | ----------------------------------------- |
| **Kaggle**  | Gemini Studio Key via Secrets | `GOOGLE_API_KEY`                 | Provided by the course                    |
| **Local**   | Vertex / Gemini API Key       | `GCP_API_KEY`                    | Loaded via `utils_env.load_environment()` |
| **GCP VM**  | Service Account JSON (IAM)    | `GOOGLE_APPLICATION_CREDENTIALS` | Auto-detected via ADC                     |

---

## âš™ï¸ Quickstart Guide

1ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

or minimal:
pip install duckdb python-dotenv pillow plotly pandas

---

2ï¸âƒ£ Run the Pipeline

from src.pipeline import run_pipeline
from src.utils_env import load_environment
from agents.ocr_agent import OCRAgent
from agents.threading_agent import ThreadingAgent
from agents.extraction_agent import ExtractionAgent

cfg = load_environment()

ocr = OCRAgent.from_env(cfg)
threader = ThreadingAgent()
extract = ExtractionAgent.from_env(cfg)

pages, sequences = run_pipeline(
    manifest_df,
    ocr_agent=ocr,
    threading_agent=threader,
    extraction_agent=extract,
)

print(f"âœ… Pipeline complete. Pages: {len(pages)}, Sequences: {len(sequences)}")

---

3ï¸âƒ£ Query the DuckDB Intelligence Layer

from src.search_index import open_duckdb

con = open_duckdb("data/lantern.duckdb")

results = con.sql("""
SELECT *
FROM pages
WHERE search_text LIKE '%court%'
ORDER BY sequence_id, sequence_order
LIMIT 20;
""").df()

results.head()

---

## ğŸ“Š Notebook Demonstration

Use:
notebooks/5_Visualization_Walkthrough.ipynb

Youâ€™ll be able to:
- Display scanned pages
- Preview OCR output
- Explore extracted insights
- Analyze threads
- Run DuckDB keyword search

---

## ğŸ… Why LANTERN Stands Out

âœ” Professional multi-agent design
âœ” Clear fallback chain for OCR robustness
âœ” Deterministic + LLM-powered extraction options
âœ” Thread reconstruction for hard document sets
âœ” DuckDB search layer for instant intelligence
âœ” Polished diagrams, documentation & demo workflow

---

## ğŸ‘¤ Author

**Payton K. Maurer**  
Senior Data Strategy & Digital Analytics Consultant  
Specializing in multi-agent systems, GA4/GTM architecture, and large-scale data pipelines.  

- ğŸ“§ payton.k.maurer@gmail.com   
- ğŸŒ LinkedIn: [https://www.linkedin.com/in/paytonmaurer](https://www.linkedin.com/in/paytonmaurer)

---

## ğŸ¤ Acknowledgements

Built for the Google AI Agents Intensive (2025).
Special thanks to the cohort leads, reviewers, and community.
